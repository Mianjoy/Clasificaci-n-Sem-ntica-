# Clasificador SemÃ¡ntico de Textos ClÃ¡sicos mediante Modelos Masivos de Lenguaje

[![GitHub Pages](https://img.shields.io/badge/GitHub%20Pages-Live-blue)](https://USERNAME.github.io/clasificador-textos-clasicos/)
[![Python](https://img.shields.io/badge/Python-3.8+-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

Sistema de Inteligencia Artificial para la clasificaciÃ³n automÃ¡tica de fragmentos de textos clÃ¡sicos en tres categorÃ­as temÃ¡ticas y filosÃ³ficas: **AretÃ©**, **Poder y PolÃ­tica**, y **RelaciÃ³n entre Humanos y Dioses**.

ğŸŒ **[Ver pÃ¡gina en GitHub Pages](https://USERNAME.github.io/clasificador-textos-clasicos/)**

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema completo de clasificaciÃ³n de textos utilizando tÃ©cnicas de Deep Learning y Fine-Tuning sobre modelos de lenguaje pre-entrenados. El sistema estÃ¡ diseÃ±ado para ser accesible a investigadores en humanidades sin conocimientos tÃ©cnicos previos.

## ğŸ¯ CaracterÃ­sticas Principales

- âœ… **Base de Datos Estructurada**: MigraciÃ³n de datos Excel a SQLite
- âœ… **Preprocesamiento Avanzado**: Limpieza y normalizaciÃ³n de textos
- âœ… **Balanceo de Clases**: TÃ©cnica SMOTE+Tomek para balancear el dataset
- âœ… **Fine-Tuning de LLM**: Entrenamiento con DistilBERT
- âœ… **EvaluaciÃ³n Completa**: Matriz de confusiÃ³n y mÃ©tricas detalladas
- âœ… **Interfaz Web Moderna**: GUI accesible y estÃ©ticamente diseÃ±ada
- âœ… **Interpretabilidad**: Muestra probabilidades por categorÃ­a

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Pasos de InstalaciÃ³n

1. **Clonar o descargar el repositorio**

2. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

3. **Descargar recursos de NLTK** (se descargan automÃ¡ticamente, pero si hay problemas):
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
```

## ğŸ“– Uso

### ğŸ”„ Clonar el Repositorio

**âš ï¸ Importante**: Este repositorio usa Git LFS para archivos grandes. AsegÃºrate de tener Git LFS instalado antes de clonar:

```bash
# Instalar Git LFS (si no lo tienes)
git lfs install

# Clonar el repositorio
git clone https://github.com/USERNAME/clasificador-textos-clasicos.git
cd clasificador-textos-clasicos
```

Si ya clonaste el repositorio sin Git LFS instalado, ejecuta:
```bash
git lfs install
git lfs pull
```

### 1. Preparar los Datos

**OpciÃ³n A: Usar la base de datos incluida (Recomendado)**
El repositorio incluye la base de datos `data/textos_clasicos.db` con los datos ya importados. Puedes saltarte el paso de importaciÃ³n.

**OpciÃ³n B: Importar desde Excel**
Si prefieres usar tus propios datos, asegÃºrese de que los archivos Excel (`0.xlsx`, `1.xlsx`, ..., `6.xlsx`) estÃ©n en el directorio raÃ­z del proyecto y ejecute:
```bash
python database.py
```

### 2. Usar el Modelo Entrenado (Incluido en el Repositorio)

**Si clonas este repositorio desde GitHub**, el modelo ya estÃ¡ entrenado y listo para usar. Puedes iniciar directamente la aplicaciÃ³n web:

```bash
python app.py
```

O usar el script de inicio:

```bash
# Windows
INICIAR_APP.bat

# Linux/Mac
python app.py
```

### 3. Entrenar un Modelo Nuevo (Opcional)

Si deseas reentrenar el modelo desde cero:

**OpciÃ³n A: Script Python (Recomendado)**
```bash
python run_pipeline.py
```

Este script ejecuta:
- ImportaciÃ³n de datos desde Excel a base de datos SQLite (si no existe la BD)
- Preprocesamiento y balanceo de clases
- Entrenamiento del modelo con fine-tuning
- EvaluaciÃ³n del modelo y generaciÃ³n de mÃ©tricas

### 4. Ejecutar Componentes Individuales

#### Importar datos a base de datos:
```bash
python database.py
```

#### Preprocesar datos:
```bash
python preprocessing.py
```

#### Entrenar modelo:
```bash
python train_model.py
```

#### Evaluar modelo:
```bash
python evaluate_model.py
```

### 5. Iniciar la AplicaciÃ³n Web

#### Desarrollo:
```bash
python app.py
```

#### ProducciÃ³n (con Gunicorn):
```bash
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```

Luego, abra su navegador en: `http://localhost:5000`

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ app.py                  # AplicaciÃ³n web Flask
â”œâ”€â”€ config.py               # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ database.py             # GestiÃ³n de base de datos
â”œâ”€â”€ preprocessing.py        # Preprocesamiento y balanceo
â”œâ”€â”€ train_model.py          # Entrenamiento del modelo
â”œâ”€â”€ evaluate_model.py       # EvaluaciÃ³n del modelo
â”œâ”€â”€ run_pipeline.py         # Script principal
â”œâ”€â”€ requirements.txt        # Dependencias
â”œâ”€â”€ README.md              # Este archivo
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Interfaz web
â”œâ”€â”€ data/
â”‚   â””â”€â”€ textos_clasicos.db # Base de datos SQLite (incluida en el repo)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ clasificador_textos_clasicos/  # Modelo entrenado (incluido en el repo)
â”‚       â”œâ”€â”€ pytorch_model.bin          # Modelo entrenado final
â”‚       â”œâ”€â”€ config.json                # ConfiguraciÃ³n del modelo
â”‚       â”œâ”€â”€ tokenizer*.json            # Archivos del tokenizer
â”‚       â””â”€â”€ ...                        # Otros archivos necesarios
â”œâ”€â”€ results/               # Resultados de evaluaciÃ³n (se generan al evaluar)
â””â”€â”€ logs/                  # Logs de entrenamiento (excluidos del repo)
```

## ğŸ”§ ConfiguraciÃ³n

Puede modificar los parÃ¡metros en `config.py`:

- `MODEL_NAME`: Modelo base a usar (por defecto: `distilbert-base-uncased`)
- `MAX_LENGTH`: Longitud mÃ¡xima de tokens (por defecto: 512)
- `BATCH_SIZE`: TamaÃ±o de lote (por defecto: 16)
- `LEARNING_RATE`: Tasa de aprendizaje (por defecto: 2e-5)
- `NUM_EPOCHS`: NÃºmero de Ã©pocas (por defecto: 3)

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

El sistema genera:

- **Matriz de ConfusiÃ³n**: VisualizaciÃ³n de aciertos y errores
- **PrecisiÃ³n (Precision)**: Por clase y promedio ponderado
- **Sensibilidad (Recall)**: Por clase y promedio ponderado
- **F1-Score**: Por clase y promedio ponderado
- **Accuracy**: PrecisiÃ³n general

**Criterio de AceptaciÃ³n**: F1-Score â‰¥ 0.8

Los resultados se guardan en:
- `results/matriz_confusion.png`
- `results/reporte_evaluacion.csv`

## ğŸ¨ Interfaz de Usuario

La interfaz web ofrece:

- DiseÃ±o moderno y limpio
- Entrada de texto intuitiva
- VisualizaciÃ³n clara de resultados
- Probabilidades por categorÃ­a con barras de progreso
- DiseÃ±o responsive (adaptable a mÃ³viles)

## ğŸ”¬ MetodologÃ­a

### 1. Ingesta y GestiÃ³n de Datos
- MigraciÃ³n de Excel a SQLite
- Estructura normalizada con integridad referencial
- Consultas optimizadas

### 2. Preprocesamiento
- Limpieza de texto (normalizaciÃ³n, eliminaciÃ³n de caracteres especiales)
- TokenizaciÃ³n y lematizaciÃ³n
- Balanceo con SMOTE+Tomek Links

### 3. Modelado
- Fine-tuning de DistilBERT (modelo ligero y eficiente)
- Transfer Learning desde modelo pre-entrenado
- Entrenamiento con validaciÃ³n temprana

### 4. EvaluaciÃ³n
- DivisiÃ³n train/validation/test (70/10/20)
- MÃ©tricas estÃ¡ndar de clasificaciÃ³n
- Visualizaciones profesionales

## ğŸ“ Notas TÃ©cnicas

- **Modelo Base**: DistilBERT es una versiÃ³n ligera de BERT, ideal para tareas de clasificaciÃ³n de texto
- **Balanceo**: SMOTE+Tomek combina oversampling sintÃ©tico con limpieza de ejemplos ambiguos
- **GPU**: El sistema detecta automÃ¡ticamente si hay GPU disponible y usa FP16 para acelerar el entrenamiento

## ğŸ› SoluciÃ³n de Problemas

### Error: "Modelo no encontrado"
**Si clonaste desde GitHub**: El modelo ya estÃ¡ incluido. Si aparece este error, verifica que exista `models/clasificador_textos_clasicos/pytorch_model.bin`

**Si estÃ¡s entrenando desde cero**: Ejecute `python train_model.py` o `python run_pipeline.py`

### Error: "Base de datos vacÃ­a"
**Si clonaste desde GitHub**: La base de datos ya estÃ¡ incluida en `data/textos_clasicos.db`. Si aparece este error, verifica que el archivo existe.

**Si estÃ¡s usando tus propios datos**: Ejecute `python database.py` para importar los datos desde Excel

### Error al instalar dependencias
AsegÃºrese de tener Python 3.8+ y actualice pip:
```bash
pip install --upgrade pip
```

## ğŸŒ GitHub Pages

Este proyecto incluye una pÃ¡gina web estÃ¡tica en [GitHub Pages](https://USERNAME.github.io/clasificador-textos-clasicos/) que muestra informaciÃ³n sobre el proyecto, caracterÃ­sticas, instalaciÃ³n y uso.

**Para activar GitHub Pages:**
1. Ve a Settings â†’ Pages en tu repositorio de GitHub
2. Selecciona la fuente: `Deploy from a branch`
3. Selecciona la rama: `main` o `master`
4. Selecciona la carpeta: `/docs`
5. Haz clic en Save
6. Tu pÃ¡gina estarÃ¡ disponible en: `https://USERNAME.github.io/clasificador-textos-clasicos/`

## ğŸš€ Subir el Proyecto a GitHub

Si deseas publicar este proyecto en GitHub, consulta las guÃ­as:

- **[GUIA_RAPIDA_GITHUB.md](GUIA_RAPIDA_GITHUB.md)** - GuÃ­a rÃ¡pida paso a paso âš¡
- **[GITHUB_SETUP.md](GITHUB_SETUP.md)** - GuÃ­a detallada completa ğŸ“–

**OpciÃ³n 1: Usar el script automÃ¡tico (Recomendado)**

```powershell
# Windows PowerShell
.\subir_a_github.ps1
```

Este script configurarÃ¡ Git LFS, prepararÃ¡ los archivos y te guiarÃ¡ paso a paso.

**OpciÃ³n 2: Comandos manuales**

```bash
# 1. Inicializar Git LFS
git lfs install

# 2. Agregar archivos
git add .
git commit -m "Initial commit: Clasificador de Textos ClÃ¡sicos con modelo entrenado"

# 3. Configurar repositorio remoto (reemplaza USERNAME)
git remote add origin https://github.com/USERNAME/clasificador-textos-clasicos.git
git branch -M main

# 4. Subir a GitHub
git push -u origin main
```

**âš ï¸ Nota importante**: El modelo entrenado es grande (>200MB), por lo que se requiere Git LFS para subirlo a GitHub. Los scripts incluidos configuran esto automÃ¡ticamente.

**Nota importante**: El repositorio incluye:
- âœ… Base de datos entrenada (`data/textos_clasicos.db`)
- âœ… Modelo entrenado completo (`models/clasificador_textos_clasicos/`)
- âœ… Todos los archivos necesarios para usar el sistema inmediatamente

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¥ Autor

Desarrollado como proyecto acadÃ©mico para clasificaciÃ³n semÃ¡ntica de textos clÃ¡sicos.

## ğŸ™ Agradecimientos

- Hugging Face por los modelos pre-entrenados
- Comunidad de cÃ³digo abierto por las librerÃ­as utilizadas

---

**VersiÃ³n**: 1.0.0  
**Ãšltima actualizaciÃ³n**: 2024

